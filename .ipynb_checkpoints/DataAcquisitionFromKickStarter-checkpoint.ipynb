{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f44825",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import concurrent.futures\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d08ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_driver():\n",
    "    firefox_driver_path = \"/Users/reembeniluz/Downloads/geckodriver\"  # Replace with the actual path to the GeckoDriver executable\n",
    "    \n",
    "    # Configure proxy settings\n",
    "    proxy_host = \"p.webshare.io\"  # Replace with your Webshare proxy host\n",
    "    proxy_port = \"80\"  # Replace with your Webshare proxy port\n",
    "    proxy_username = \"ioqzyjgy-rotate\"  # Replace with your Webshare proxy username\n",
    "    proxy_password = \"urcueqpitm55\"  # Replace with your Webshare proxy password\n",
    "\n",
    "    # Set up Firefox options\n",
    "    options = Options()\n",
    "    options.add_argument('-headless')\n",
    "    options.add_argument(\"--private\")\n",
    "    # Configure proxy server\n",
    "    proxy_string = f\"{proxy_username}:{proxy_password}@{proxy_host}:{proxy_port}\"\n",
    "    options.add_argument(f\"--proxy-server={proxy_string}\")\n",
    "    # Create Firefox WebDriver instance\n",
    "    driver = webdriver.Firefox(service=Service(firefox_driver_path), options=options)\n",
    "    print(\"Driver was created\")\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1b3ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_page(url):\n",
    "    driver = initialize_driver()\n",
    "    driver.get(url)\n",
    "    time.sleep(random.randint(2, 4))\n",
    "    links = []\n",
    "    extract_project_links(driver, links)\n",
    "    driver.quit()\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d6de1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_project_links(driver, links):\n",
    "    page_links = driver.execute_script(\"\"\"\n",
    "        const elements = document.querySelectorAll('div.relative.self-start a[href].block.img-placeholder.w100p');\n",
    "        const filteredLinks = [];\n",
    "        elements.forEach(element => {\n",
    "            const href = element.getAttribute('href');\n",
    "            if (!href.includes('ref=recommendation-no-result-discoverpage')) {\n",
    "                filteredLinks.push(href);\n",
    "            }\n",
    "        });\n",
    "        return filteredLinks;\n",
    "    \"\"\")\n",
    "    links.extend(page_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04c29f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def projects_links_list_from_website(url, start_page, end_page, links,seed):\n",
    "    page_seed = seed\n",
    "    for seed_count in range(1, 2):\n",
    "        page_urls = [url.replace(f'page={start_page}', f'page={page}') for page in range(start_page, end_page+1)]\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "            futures = [executor.submit(scrape_page, page_url) for page_url in page_urls]\n",
    "\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                result = future.result()\n",
    "                print(result)\n",
    "                links.extend(result)\n",
    "                future.done()  # Close the thread when it finishes\n",
    "\n",
    "            url = url.replace(f'seed={page_seed}', f'seed={page_seed+1}')\n",
    "            page_seed += 1\n",
    "\n",
    "        # Move the seed_count loop inside the 'with' block\n",
    "        # Wait for all threads to finish before moving to the next iteration\n",
    "        for future in futures:\n",
    "            future.result()\n",
    "    print('bye')\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1e1377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_project_data(link):\n",
    "    driver = initialize_driver()\n",
    "    driver.get(link)\n",
    "    time.sleep(2)\n",
    "    element = driver.find_element(By.XPATH, '//*[@id=\"react-project-header\"]')\n",
    "    days_left_element = driver.find_element(By.XPATH, '/html/body/main/div/div/div[1]/div/div[1]/div[1]/div[2]/div[2]/div[3]/div/div/span[1]')\n",
    "    data_initial = element.get_attribute(\"data-initial\")\n",
    "    json_data = json.loads(data_initial)\n",
    "    project_name = json_data['project']['name']\n",
    "    project_link = link\n",
    "    currency = json_data['project']['currency']\n",
    "    location = json_data['project']['location']['displayableName']\n",
    "    try:\n",
    "        parent_category = json_data['project']['category']['parentCategory']['name']\n",
    "    except:\n",
    "        parent_category = 'none'\n",
    "    category_name = json_data['project']['category']['name']\n",
    "    is_project_we_love = json_data['project']['isProjectWeLove']\n",
    "    percent_funded = json_data['project']['percentFunded']\n",
    "    goal_amount = json_data['project']['goal']['amount']\n",
    "    pledged_amount = json_data['project']['pledged']['amount']\n",
    "    duration = json_data['project']['duration']\n",
    "    description_length = len(json_data['project']['description'])\n",
    "    video_elements = driver.find_elements(By.TAG_NAME, \"video\")\n",
    "    video_count = len(video_elements)\n",
    "    image_elements = driver.find_elements(By.TAG_NAME, \"img\")\n",
    "    image_count = len(image_elements)\n",
    "    days_left = days_left_element.text\n",
    "\n",
    "    try:\n",
    "        riskField = driver.find_element(By.XPATH, '//*[@id=\"risks-and-challenges\"]/p')\n",
    "        riskDescLength = len(riskField.text)\n",
    "    except:\n",
    "        riskDescLength = 0\n",
    "\n",
    "    project_info = {\n",
    "        \"Project Link\":project_link,\n",
    "        \"Project Name\": project_name,\n",
    "        \"Currency\": currency,\n",
    "        \"Location\": location,\n",
    "        \"Parent Category\": parent_category,\n",
    "        \"Category Name\": category_name,\n",
    "        \"Is Project We Love\": is_project_we_love,\n",
    "        \"Percent Funded\": percent_funded,\n",
    "        \"Goal Amount\": goal_amount,\n",
    "        \"Pledged Amount\": pledged_amount,\n",
    "        \"Duration\": duration,\n",
    "        \"Description Length\": description_length,\n",
    "        \"Image Count\": image_count,\n",
    "        \"Video Count\": video_count,\n",
    "        \"Risk Desc Count\": riskDescLength,\n",
    "        \"Days Left\":days_left\n",
    "    }\n",
    "\n",
    "    driver.quit()\n",
    "    return project_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c74c52c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def projects_data_from_links(links,project_data_dic):\n",
    "    counter = 1\n",
    "\n",
    "    def scrape_project_data_wrapper(link):\n",
    "        driver = initialize_driver()\n",
    "        try:\n",
    "            return scrape_project_data(link)\n",
    "        finally:\n",
    "            driver.quit()\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = [executor.submit(scrape_project_data_wrapper, link) for link in links]\n",
    "\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            result = future.result()\n",
    "            project_data_dic.append(result)\n",
    "            print('finished with project:', counter)\n",
    "            counter += 1\n",
    "\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a6082e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv_table(data, filename):\n",
    "    fieldnames = [\n",
    "        \"Project Name\",\n",
    "        \"Project Link\",\n",
    "        \"Parent Category\",\n",
    "        \"Category Name\",\n",
    "        \"Location\",\n",
    "        \"Currency\",\n",
    "        \"Goal Amount\",\n",
    "        \"Pledged Amount\",\n",
    "        \"Percent Funded\",\n",
    "        \"Duration\",\n",
    "        \"Days Left\",\n",
    "        \"Description Length\",\n",
    "        \"Risk Desc Count\",\n",
    "        \"Is Project We Love\",\n",
    "        \"Image Count\",\n",
    "        \"Video Count\"\n",
    "    ]\n",
    "    with open(filename, 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206ab9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_list():\n",
    "    print(\"here\")\n",
    "    with open(\"ProjectsLinks.txt\", \"r\") as file:\n",
    "        print(\"here2\")\n",
    "        # Read the content of the file and store each line as an element in the list\n",
    "        links = file.readlines()\n",
    "        # Remove trailing newline characters from each line\n",
    "        links = [link.strip() for link in links]\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365a5cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.kickstarter.com/discover/advanced?category_id=13&sort=magic&seed=2808841&page=1\"\n",
    "\n",
    "# projects_links_list_from_website(url,1,200,links,2808841)\n",
    "project_data_dic = []\n",
    "links = load_list()\n",
    "projects_data_from_links(links,project_data_dic)\n",
    "create_csv_table(project_data_dic,'sample_projects_table_data.csv')\n",
    "print('table was created successfuly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d0758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_table(project_data_dic,'projects_table_data.csv')\n",
    "print('table was created successfuly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8d5217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42582f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b9c21e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8824de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca347a71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
